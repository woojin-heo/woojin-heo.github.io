---
layout: post
title:  "[딥러닝] 이미지 인식 - 브랜드 로고 탐지 (4) YOLO"
date:   2020-01-10T14:25:52-05:00
author: woodi
categories: Projects
---
이번 포스트에서는 YOLO 알고리즘으로 객체를 탐지(Object Detection)하는 방법에 대하여 간략히 설명하고자 한다.

- - -

#### YOLO Training dataset 만들기
YOLO의 트레이닝 데이터는 아래와 같이 만들어진다.

![img](C:/woojin-heo.github.io/_posts/img/yolo_training.png)

위의 노란색 box를 만들어주면 아래의 내용이 담긴 txt파일이 생성된다.

```
Label, x, y, width, height
4 0.332031 0.818056 0.220313 0.358333
4 0.632813 0.467361 0.221875 0.437500
```
이러한 트레이닝 데이터를 만드는 YOLO-MARK 프로그램의 설치와 사용은 [이 곳](http://)을 참고했다.

*이때, 이후에 파이썬에서 실행할 수 있는 darkflow를 이용 (yolo v2)할 것인지, c언어 기반의 darknet(yolo v3)을 이용할 것인지에 따라서 다른 마크 프로그램을 사용해야 하는 점을 유의하자. 이 프로젝트에서는 yolo v3를 이용하기 위해 darknet을 사용했다. *
- - -

#### YOLO가 Detection을 하는 방법
위와 같은, 트레이닝을 위해 만들어 준 box의 정보를 이용해 각 객체별로 다른 모양의 box를 생성한다. 이를 **Anchor box**라고 한다.

예를들어, 아래의 사진에서 ==사람==과 ==맥주의 로고==를 찾는다고 가정해보자.
![img](C:/woojin-heo.github.io/_posts/img/yolo_skj.png)


그렇다면  우리가 트레이닝 시킨 데이터에서 box의 모양은 아래의 그림과 같을 것이다.평균적으로 맥주 로고는 가로로 긴 형태, 사람은 세로로 긴 형태이다.
![img](C:/woojin-heo.github.io/_posts/img/yolo_anchorbox.png)

즉, 트레이닝 데이터에서 만든 box의 가로,세로 비율을 이용해 anchor box의 종횡비가 결정되며, 찾아야 하는 객체의 수만큼 각기 다른 종횡비를 가진 anchor box가 생성된다.

이러한 각 객체들의 anchor box들은 다양한 사이즈로 이미지에 적용되어 해당 box 내에 해당 객체가 포함되는지 찾는다.
![img](C:/woojin-heo.github.io/_posts/img/yolo_redbox1.png)![img](C:/woojin-heo.github.io/_posts/img/yolo_redbox2.png)
![img](C:/woojin-heo.github.io/_posts/img/yolo_greenbox1.png)![img](C:/woojin-heo.github.io/_posts/img/yolo_greenbox2.png)

실제로는 위와 같이 순차적으로 적용되는 것이 아니라, 아래와 같이 한번에 진행된다.
![img](C:/woojin-heo.github.io/_posts/img/yolo_allboxes.png)

각각의 anchor box들은 그 안에 객체가 있을 확률을 출력하는데 이를 **confidence score**라고 한다. 위에서의 사진과 같이 각 anchor box들이 한 사물에 여러개가 겹쳐져서 물체를 찾기 때문에 아래와 같이 하나의 객체에 여러개의 anchor box가 각각의 confidence score를 출력한다.
![img](C:/woojin-heo.github.io/_posts/img/yolo_confidence_scores.png)

이때, 하나의 객체당 하나의 box만 생성 되어야 하므로 이 중 가장 높은 confidence score를 갖는 box만 남겨두고 나머지는 제거한다. 이를 non max suppression이라고 한다. ^이 과정에서의 IOU개념은 CNN을 포스팅 하게 된다면 좀 더 자세히 다루어보겠다.^

이 과정을 거치면 이래와 같이 하나의 객체를 찾는 box가 생성되어 객체가 있는 위치를 **localization** 하고 그것이 어떤 사물인지를 분류해주는 **classification**이 동시에(one stage) 이루어 진 결과를 볼 수 있다.
![img](C:/woojin-heo.github.io/_posts/img/yolo_final_box.png)

다음 포스트에서는 darknet(yolo v3)을 이용해 트레이닝 데이터로 모델을 학습시키고, 실제로 테스트를 하는 법을 작성해보겠다.

2020년 1월 10일 오후 9시 30분. woodi 작성


